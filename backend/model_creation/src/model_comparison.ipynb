{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'nltk,'\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk, joblib, pandas, tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import chardet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './../datasets/SMS Spam Collection/final/spam.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "df = pd.read_csv(filename, encoding=result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I am late,so call you tomorrow morning.take ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>U r too much close to my heart. If u go away i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Wait  &amp;lt;#&amp;gt;  min..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Can you call me plz. Your number shows out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  I am late,so call you tomorrow morning.take ca...\n",
       "1       0  U r too much close to my heart. If u go away i...\n",
       "2       0                             Wait  &lt;#&gt;  min..\n",
       "3       0  Can you call me plz. Your number shows out of ...\n",
       "4       0  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning\n",
    "df['text'] = df['text'].apply(lambda x: x.lower()) # convert to lower case\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('[^a-z\\s]', '', x)) # remove special characters and numbers\n",
    "\n",
    "# Tokenization\n",
    "df['text'] = df['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Stop Word Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['text'] = df['text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Convert list of words back to string\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Vectorization (TF-IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the models\n",
    "models = [\n",
    "    {'label': 'Logistic Regression', 'model': LogisticRegression(C=0.1, random_state=42)},\n",
    "    {'label': 'Naive Bayes', 'model': MultinomialNB()},\n",
    "    {'label': 'Random Forest', 'model': RandomForestClassifier(random_state=42)},\n",
    "    {'label': 'Support Vector Machine', 'model': LinearSVC(C=0.1, random_state=42)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing the models\n",
    "results = []\n",
    "for m in models:\n",
    "    model = m['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Implement cross validation\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    \n",
    "    results.append([m['label'], accuracy, precision, recall, f1, cv_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with the results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Cross-Validation Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Cross-Validation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.886288</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.906276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.933110</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.936402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.936455</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>0.944770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.919861</td>\n",
       "      <td>0.932218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1 Score  \\\n",
       "0     Logistic Regression  0.886288   0.991803  0.785714  0.876812   \n",
       "1             Naive Bayes  0.933110   0.929487  0.941558  0.935484   \n",
       "2           Random Forest  0.936455   0.992701  0.883117  0.934708   \n",
       "3  Support Vector Machine  0.923077   0.992481  0.857143  0.919861   \n",
       "\n",
       "   Cross-Validation Score  \n",
       "0                0.906276  \n",
       "1                0.936402  \n",
       "2                0.944770  \n",
       "3                0.932218  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
